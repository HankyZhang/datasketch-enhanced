"""
æ–¹æ³•3å‚æ•°è°ƒä¼˜ï¼šK-Means HNSWç³»ç»Ÿ + Multi-Pivotæ‰©å±• (Method 3 Parameter Tuning: K-Means HNSW System + Multi-Pivot Extension)

æœ¬æ¨¡å—åŸºäº tune_kmeans_hnsw.pyï¼Œé¢å¤–æ·»åŠ äº†Multi-Pivot KMeans HNSWçš„è¯„ä¼°å’Œå¯¹æ¯”ã€‚
æä¾›äº”ç§æ–¹æ¡ˆçš„å…¨é¢å¯¹æ¯”è¯„ä¼°ï¼š

1. HNSWåŸºçº¿ (HNSW Baseline) - çº¯HNSWç´¢å¼•
2. çº¯K-Means (Pure K-Means) - ä»…ä½¿ç”¨K-Meansèšç±»
3. Hybrid HNSW - åŸºäºHNSWå±‚çº§çš„æ··åˆç´¢å¼•
4. KMeans HNSW (å•æ¢çº½) - å•æ¢çº½K-Means HNSWæ··åˆç³»ç»Ÿ
5. Multi-Pivot KMeans HNSW (å¤šæ¢çº½) - å¤šæ¢çº½K-Means HNSWæ··åˆç³»ç»Ÿ

åŠŸèƒ½ç‰¹æ€§:
- å…¨é¢çš„å‚æ•°æ‰«æå’Œä¼˜åŒ–
- äº”ç§æ–¹æ¡ˆçš„åŸºå‡†å¯¹æ¯”è¯„ä¼°
- å¬å›ç‡å’ŒæŸ¥è¯¢æ—¶é—´åˆ†æ
- Multi-Pivotæ¢çº½ç­–ç•¥æµ‹è¯•
- è‡ªé€‚åº”å‚æ•°è°ƒæ•´
- ç»“æœä¿å­˜å’Œåˆ†æ

This module extends tune_kmeans_hnsw.py with Multi-Pivot KMeans HNSW evaluation.
It provides comprehensive comparison evaluation for five approaches.
"""

import os
import sys
import time
import json
import argparse
import random
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from itertools import product

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ (Add parent directory to path)
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from method3.kmeans_hnsw import KMeansHNSW
from method3.kmeans_hnsw_multi_pivot import KMeansHNSWMultiPivot
from hnsw.hnsw import HNSW
# å¼•å…¥ Hybrid HNSW ç»“æ„ç”¨äºå¯¹æ¯”è¯„ä¼° (Import Hybrid HNSW for comparative evaluation)
from hybrid_hnsw.hnsw_hybrid import HNSWHybrid
# ä½¿ç”¨sklearn MiniBatchKMeansä½œä¸ºçº¯k-meansåŸºçº¿ (Switch to sklearn MiniBatchKMeans for pure k-means baseline)
from sklearn.cluster import MiniBatchKMeans


class KMeansHNSWMultiPivotEvaluator:
    """
    K-Means HNSWç³»ç»Ÿæ€§èƒ½å…¨é¢è¯„ä¼°å™¨ (å«Multi-Pivotæ‰©å±•)
    (Comprehensive evaluator for K-Means HNSW system performance with Multi-Pivot extension)
    
    æ­¤ç±»æä¾›äº†å¯¹K-Means HNSWç³»ç»Ÿçš„å…¨é¢è¯„ä¼°åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - çœŸå®å€¼(Ground Truth)è®¡ç®—
    - å¬å›ç‡è¯„ä¼°
    - å‚æ•°æ‰«æå’Œä¼˜åŒ–
    - ä¸åŸºçº¿æ–¹æ³•çš„æ€§èƒ½å¯¹æ¯” (åŒ…æ‹¬Multi-Pivotæ–¹æ¡ˆ)
    """
    
    def __init__(
        self, 
        dataset: np.ndarray, 
        query_set: np.ndarray, 
        query_ids: List[int],
        distance_func: callable
    ):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨ (Initialize the evaluator)
        
        Args:
            dataset: å®Œæ•´æ•°æ®é›†å‘é‡ (Full dataset vectors) - shape: [n_vectors, dim]
            query_set: æŸ¥è¯¢å‘é‡ (Query vectors) - shape: [n_queries, dim]  
            query_ids: æŸ¥è¯¢å‘é‡IDåˆ—è¡¨ (IDs for query vectors)
            distance_func: ç”¨äºçœŸå®å€¼è®¡ç®—çš„è·ç¦»å‡½æ•° (Distance function for ground truth computation)
        """
        self.dataset = dataset
        self.query_set = query_set
        self.query_ids = query_ids
        self.distance_func = distance_func
        
        # çœŸå®å€¼ç¼“å­˜ (Ground truth cache)
        self._ground_truth_cache = {}
    
    def compute_ground_truth(
        self, 
        k: int, 
        exclude_query_ids: bool = True
    ) -> Dict[int, List[Tuple[int, float]]]:
        """
        ä½¿ç”¨æš´åŠ›æœç´¢è®¡ç®—çœŸå®å€¼ (Compute ground truth using brute force search)
        
        é€šè¿‡å¯¹æ¯ä¸ªæŸ¥è¯¢å‘é‡è®¡ç®—ä¸æ‰€æœ‰æ•°æ®å‘é‡çš„è·ç¦»ï¼Œæ‰¾å‡ºçœŸæ­£çš„kä¸ªæœ€è¿‘é‚»ã€‚
        è¿™æ˜¯è¯„ä¼°å…¶ä»–ç®—æ³•å¬å›ç‡çš„æ ‡å‡†åŸºå‡†ã€‚
        
        Args:
            k: æœ€è¿‘é‚»æ•°é‡ (Number of nearest neighbors)
            exclude_query_ids: æ˜¯å¦ä»ç»“æœä¸­æ’é™¤æŸ¥è¯¢ID (Whether to exclude query IDs from results)
            
        Returns:
            å­—å…¸ï¼šæŸ¥è¯¢ID -> (è·ç¦», æ•°æ®ç´¢å¼•)å…ƒç»„åˆ—è¡¨ (Dictionary mapping query_id to list of (distance, data_index) tuples)
        """
        cache_key = (k, exclude_query_ids)
        if cache_key in self._ground_truth_cache:
            return self._ground_truth_cache[cache_key]
        
        print(f"æ­£åœ¨è®¡ç®— {len(self.query_set)} ä¸ªæŸ¥è¯¢çš„çœŸå®å€¼ (k={k}, exclude_query_ids={exclude_query_ids})...")
        start_time = time.time()
        
        ground_truth = {}
        excluded_count = 0
        
        for i, (query_vector, query_id) in enumerate(zip(self.query_set, self.query_ids)):
            distances = []
            
            for j, data_vector in enumerate(self.dataset):
                if exclude_query_ids and j == query_id:
                    excluded_count += 1
                    continue  # è·³è¿‡æŸ¥è¯¢æœ¬èº« (Skip the query itself)
                
                distance = self.distance_func(query_vector, data_vector)
                distances.append((distance, j))
            
            # æŒ‰è·ç¦»æ’åºå¹¶å–å‰kä¸ª (Sort by distance and take top-k)
            distances.sort()
            ground_truth[query_id] = distances[:k]
        
        elapsed = time.time() - start_time
        print(f"çœŸå®å€¼è®¡ç®—å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f}ç§’ï¼Œæ’é™¤äº† {excluded_count} ä¸ªæ•°æ®ç‚¹")
        
        self._ground_truth_cache[cache_key] = ground_truth
        return ground_truth
    
    def evaluate_recall(
        self,
        kmeans_hnsw: KMeansHNSW,
        k: int,
        n_probe: int,
        ground_truth: Optional[Dict] = None,
        exclude_query_ids: bool = True
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°K-Means HNSWç³»ç»Ÿçš„å¬å›ç‡æ€§èƒ½ (Evaluate recall performance of the K-Means HNSW system)
        """
        if ground_truth is None:
            ground_truth = self.compute_ground_truth(k, exclude_query_ids)
        
        print(f"æ­£åœ¨è¯„ä¼° {len(self.query_set)} ä¸ªæŸ¥è¯¢çš„å¬å›ç‡ (k={k}, n_probe={n_probe})...")
        start_time = time.time()
        
        total_correct = 0
        total_expected = len(self.query_set) * k
        query_times = []
        individual_recalls = []
        
        for i, (query_vector, query_id) in enumerate(zip(self.query_set, self.query_ids)):
            # Get ground truth for this query
            true_neighbors = {neighbor_id for _, neighbor_id in ground_truth[query_id]}
            
            # Search using K-Means HNSW
            search_start = time.time()
            results = kmeans_hnsw.search(query_vector, k=k, n_probe=n_probe)
            search_time = time.time() - search_start
            query_times.append(search_time)
            
            # Count correct results
            found_neighbors = {node_id for node_id, _ in results}
            correct = len(true_neighbors & found_neighbors)
            total_correct += correct
            
            # Individual recall for this query
            individual_recall = correct / k if k > 0 else 0.0
            individual_recalls.append(individual_recall)
        
        # Calculate final metrics
        overall_recall = total_correct / total_expected
        avg_query_time = np.mean(query_times)
        std_query_time = np.std(query_times)
        total_evaluation_time = time.time() - start_time
        
        return {
            'recall_at_k': overall_recall,
            'total_correct': total_correct,
            'total_expected': total_expected,
            'individual_recalls': individual_recalls,
            'avg_individual_recall': np.mean(individual_recalls),
            'std_individual_recall': np.std(individual_recalls),
            'avg_query_time_ms': avg_query_time * 1000,
            'std_query_time_ms': std_query_time * 1000,
            'total_evaluation_time': total_evaluation_time,
            'k': k,
            'n_probe': n_probe,
            'system_stats': kmeans_hnsw.get_stats()
        }
    
    def evaluate_multi_pivot_recall(
        self,
        multi_pivot_hnsw: KMeansHNSWMultiPivot,
        k: int,
        n_probe: int,
        ground_truth: Optional[Dict] = None,
        exclude_query_ids: bool = True
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°Multi-Pivot K-Means HNSWç³»ç»Ÿçš„å¬å›ç‡æ€§èƒ½
        (Evaluate recall performance of the Multi-Pivot K-Means HNSW system)
        """
        if ground_truth is None:
            ground_truth = self.compute_ground_truth(k, exclude_query_ids)
        
        print(f"æ­£åœ¨è¯„ä¼°Multi-Pivot {len(self.query_set)} ä¸ªæŸ¥è¯¢çš„å¬å›ç‡ (k={k}, n_probe={n_probe})...")
        start_time = time.time()
        
        total_correct = 0
        total_expected = len(self.query_set) * k
        query_times = []
        individual_recalls = []
        
        for i, (query_vector, query_id) in enumerate(zip(self.query_set, self.query_ids)):
            # Get ground truth for this query
            true_neighbors = {neighbor_id for _, neighbor_id in ground_truth[query_id]}
            
            # Search using Multi-Pivot K-Means HNSW
            search_start = time.time()
            results = multi_pivot_hnsw.search(query_vector, k=k, n_probe=n_probe)
            search_time = time.time() - search_start
            query_times.append(search_time)
            
            # Count correct results
            found_neighbors = {node_id for node_id, _ in results}
            correct = len(true_neighbors & found_neighbors)
            total_correct += correct
            
            # Individual recall for this query
            individual_recall = correct / k if k > 0 else 0.0
            individual_recalls.append(individual_recall)
        
        # Calculate final metrics
        overall_recall = total_correct / total_expected
        avg_query_time = np.mean(query_times)
        std_query_time = np.std(query_times)
        total_evaluation_time = time.time() - start_time
        
        return {
            'recall_at_k': overall_recall,
            'total_correct': total_correct,
            'total_expected': total_expected,
            'individual_recalls': individual_recalls,
            'avg_individual_recall': np.mean(individual_recalls),
            'std_individual_recall': np.std(individual_recalls),
            'avg_query_time_ms': avg_query_time * 1000,
            'std_query_time_ms': std_query_time * 1000,
            'total_evaluation_time': total_evaluation_time,
            'k': k,
            'n_probe': n_probe,
            'system_stats': multi_pivot_hnsw.get_stats()
        }

    def evaluate_hnsw_baseline(
        self,
        base_index: HNSW,
        k: int,
        ef: int,
        ground_truth: Dict
    ) -> Dict[str, Any]:
        """Evaluate recall using ONLY the base HNSW index (Phase 1)."""
        query_times = []
        total_correct = 0
        total_expected = len(self.query_set) * k
        individual_recalls = []
        
        print(f"ğŸ” è¯„ä¼°HNSWåŸºçº¿æ€§èƒ½ (k={k}, ef={ef})...")
        
        for query_vector, query_id in zip(self.query_set, self.query_ids):
            true_neighbors = {node_id for _, node_id in ground_truth[query_id]}
            
            t0 = time.time()
            results = base_index.query(query_vector, k=k, ef=ef)
            dt = time.time() - t0
            query_times.append(dt)
            
            found = {nid for nid, _ in results}
            correct = len(true_neighbors & found)
            total_correct += correct
            
            individual_recall = correct / k if k > 0 else 0.0
            individual_recalls.append(individual_recall)
        
        avg_recall = np.mean(individual_recalls)
        print(f"  HNSWåŸºçº¿å¬å›ç‡: {avg_recall:.4f} (æ€»è®¡ {total_correct}/{total_expected})")
        
        return {
            'phase': 'baseline_hnsw',
            'ef': ef,
            'recall_at_k': total_correct / total_expected if total_expected else 0.0,
            'avg_query_time_ms': float(np.mean(query_times) * 1000),
            'std_query_time_ms': float(np.std(query_times) * 1000),
            'total_correct': total_correct,
            'total_expected': total_expected,
            'individual_recalls': individual_recalls,
            'avg_individual_recall': float(np.mean(individual_recalls)),
            'std_individual_recall': float(np.std(individual_recalls))
        }

    def evaluate_hybrid_hnsw(
        self,
        hybrid_index: 'HNSWHybrid',
        k: int,
        n_probe: int,
        ground_truth: Dict
    ) -> Dict[str, Any]:
        """Evaluate recall for level-based Hybrid HNSW (parents from HNSW levels)."""
        query_times = []
        total_correct = 0
        total_expected = len(self.query_set) * k
        individual_recalls = []

        for query_vector, query_id in zip(self.query_set, self.query_ids):
            true_neighbors = {node_id for _, node_id in ground_truth[query_id]}
            t0 = time.time()
            results = hybrid_index.search(query_vector, k=k, n_probe=n_probe)
            dt = time.time() - t0
            query_times.append(dt)
            found = {nid for nid, _ in results}
            correct = len(true_neighbors & found)
            total_correct += correct
            individual_recalls.append(correct / k if k > 0 else 0.0)

        return {
            'phase': 'hybrid_hnsw_level',
            'n_probe': n_probe,
            'recall_at_k': total_correct / total_expected if total_expected else 0.0,
            'avg_query_time_ms': float(np.mean(query_times) * 1000),
            'std_query_time_ms': float(np.std(query_times) * 1000),
            'total_correct': total_correct,
            'total_expected': total_expected,
            'individual_recalls': individual_recalls,
            'avg_individual_recall': float(np.mean(individual_recalls)),
            'std_individual_recall': float(np.std(individual_recalls)),
            'hybrid_stats': hybrid_index.get_stats()
        }

    def _evaluate_pure_kmeans_from_existing(
        self, 
        kmeans_hnsw: KMeansHNSW, 
        k: int, 
        ground_truth: Dict, 
        n_probe: int = 1
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨KMeansHNSWå†…éƒ¨å·²æœ‰çš„èšç±»ç»“æœè¯„ä¼°çº¯K-Meansæ€§èƒ½
        é¿å…é‡å¤èšç±»ï¼Œç›´æ¥å¤ç”¨å·²è®­ç»ƒçš„æ¨¡å‹å’Œæ•°æ®æ˜ å°„
        """
        print(f"å¤ç”¨ç°æœ‰èšç±»è¯„ä¼°çº¯K-Means (n_clusters={kmeans_hnsw.n_clusters}, n_probe={n_probe})...")
        
        # ç›´æ¥ä½¿ç”¨KMeansHNSWå†…éƒ¨çš„èšç±»ç»“æœ
        kmeans_model = kmeans_hnsw.kmeans_model
        centers = kmeans_model.cluster_centers_
        n_clusters = centers.shape[0]
        
        # è·å–ä¸èšç±»æ—¶ç›¸åŒçš„æ•°æ®é›†å’Œç´¢å¼•æ˜ å°„
        kmeans_dataset = kmeans_hnsw._extract_dataset_vectors()
        labels = kmeans_model.labels_
        
        # æ„å»ºèšç±»åˆ°æˆå‘˜çš„æ˜ å°„
        clusters = [[] for _ in range(n_clusters)]
        dataset_idx_to_original_id = list(kmeans_hnsw.base_index.keys())
        
        for dataset_idx, cluster_id in enumerate(labels):
            original_id = dataset_idx_to_original_id[dataset_idx]
            clusters[cluster_id].append((dataset_idx, original_id))
        
        query_times = []
        total_correct = 0
        total_expected = len(self.query_set) * k
        individual_recalls = []
        
        # Cap n_probe to number of clusters
        n_probe_eff = min(n_probe, n_clusters)
        
        for query_vector, query_id in zip(self.query_set, self.query_ids):
            search_start = time.time()
            
            # è®¡ç®—åˆ°èšç±»ä¸­å¿ƒçš„è·ç¦»
            diffs = centers - query_vector
            distances_to_centroids = np.linalg.norm(diffs, axis=1)
            
            # è·å–æœ€è¿‘çš„n_probeä¸ªèšç±»ä¸­å¿ƒ
            probe_centroids = np.argpartition(distances_to_centroids, n_probe_eff - 1)[:n_probe_eff]
            probe_centroids = probe_centroids[np.argsort(distances_to_centroids[probe_centroids])]
            
            # æ”¶é›†æ‰€æœ‰è¢«æ¢æµ‹èšç±»çš„æˆå‘˜
            all_candidates = []
            for cluster_idx in probe_centroids:
                cluster_members = clusters[cluster_idx]
                for dataset_idx, original_id in cluster_members:
                    if original_id != query_id:  # æ’é™¤æŸ¥è¯¢æœ¬èº«
                        member_vec = kmeans_dataset[dataset_idx]
                        dist = np.linalg.norm(member_vec - query_vector)
                        all_candidates.append((dist, original_id))
            
            # æŒ‰è·ç¦»æ’åºå¹¶å–top-k
            all_candidates.sort(key=lambda x: x[0])
            results = all_candidates[:k]
            found_neighbors = {original_id for _, original_id in results}
            
            search_time = time.time() - search_start
            query_times.append(search_time)
            
            # è®¡ç®—å¬å›ç‡
            true_neighbors = {neighbor_id for _, neighbor_id in ground_truth[query_id]}
            correct = len(true_neighbors & found_neighbors)
            total_correct += correct
            individual_recalls.append(correct / k if k > 0 else 0.0)
        
        overall_recall = total_correct / total_expected if total_expected > 0 else 0.0
        
        return {
            'method': 'pure_kmeans_from_existing',
            'recall_at_k': overall_recall,
            'total_correct': total_correct,
            'total_expected': total_expected,
            'individual_recalls': individual_recalls,
            'avg_individual_recall': float(np.mean(individual_recalls)),
            'std_individual_recall': float(np.std(individual_recalls)),
            'avg_query_time_ms': float(np.mean(query_times) * 1000),
            'std_query_time_ms': float(np.std(query_times) * 1000),
            'clustering_time': 0.0,  # æ²¡æœ‰é‡æ–°èšç±»ï¼Œæ—¶é—´ä¸º0
            'n_clusters': n_clusters,
            'n_probe': n_probe_eff,
            'k': k,
            'reused_existing_clustering': True
        }

    def parameter_sweep(
        self,
        base_index: HNSW,
        param_grid: Dict[str, List[Any]],
        evaluation_params: Dict[str, Any],
        max_combinations: Optional[int] = None,
        adaptive_config: Optional[Dict[str, Any]] = None,
        multi_pivot_config: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå…¨é¢çš„å‚æ•°æ‰«æä¼˜åŒ– (å«Multi-Pivotæ‰©å±•)
        (Perform comprehensive parameter sweep for optimization with Multi-Pivot extension)

        é€šè¿‡ç³»ç»Ÿæ€§åœ°æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆï¼Œæ‰¾åˆ°æœ€ä¼˜çš„K-Means HNSWé…ç½®ã€‚
        åŒ…æ‹¬åŸºçº¿HNSWã€çº¯K-Meansã€Hybrid HNSWã€å•æ¢çº½KMeans-HNSWä»¥åŠMulti-Pivot KMeans-HNSWçš„å¯¹æ¯”è¯„ä¼°ã€‚
        """
        if adaptive_config is None:
            adaptive_config = {
                'adaptive_k_children': False,
                'k_children_scale': 1.5,
                'k_children_min': 100,
                'k_children_max': None,
                'diversify_max_assignments': None,
                'repair_min_assignments': None
            }

        if multi_pivot_config is None:
            multi_pivot_config = {
                'enabled': False,
                'num_pivots': 3,
                'pivot_selection_strategy': 'line_perp_third',
                'pivot_overquery_factor': 1.2
            }

        print("å¼€å§‹K-Means HNSW + Multi-Pivot å‚æ•°æ‰«æ...")
        print(f"Multi-Pivotå¯ç”¨çŠ¶æ€: {multi_pivot_config.get('enabled', False)}")

        param_names = list(param_grid.keys())
        param_values = list(param_grid.values())
        combinations = list(product(*param_values))
        if max_combinations and len(combinations) > max_combinations:
            print(f"é™åˆ¶æµ‹è¯• {max_combinations} ä¸ªç»„åˆï¼Œæ€»å…± {len(combinations)} ä¸ª")
            combinations = random.sample(combinations, max_combinations)
        print(f"æµ‹è¯• {len(combinations)} ä¸ªå‚æ•°ç»„åˆ...")

        results: List[Dict[str, Any]] = []
        k_values = evaluation_params.get('k_values', [10])
        n_probe_values = evaluation_params.get('n_probe_values', [5, 10, 20])
        hybrid_parent_level = evaluation_params.get('hybrid_parent_level', 2)
        enable_hybrid = evaluation_params.get('enable_hybrid', True)

        # Precompute ground truths
        ground_truths: Dict[int, Dict] = {}
        for k in k_values:
            ground_truths[k] = self.compute_ground_truth(k, exclude_query_ids=False)

        for i, combination in enumerate(combinations):
            print(f"\n--- Combination {i + 1}/{len(combinations)} ---")
            params = dict(zip(param_names, combination))
            print(f"Parameters: {params}")

            try:
                phase_records: List[Dict[str, Any]] = []
                
                # Build single-pivot KMeans-HNSW system
                construction_start = time.time()
                kmeans_hnsw = KMeansHNSW(
                    base_index=base_index,
                    **params,
                    adaptive_k_children=adaptive_config['adaptive_k_children'],
                    k_children_scale=adaptive_config['k_children_scale'],
                    k_children_min=adaptive_config['k_children_min'],
                    k_children_max=adaptive_config['k_children_max'],
                    diversify_max_assignments=adaptive_config['diversify_max_assignments'],
                    repair_min_assignments=adaptive_config['repair_min_assignments']
                )
                construction_time = time.time() - construction_start
                print(f"  æ„å»ºK-Means HNSWç³»ç»Ÿè€—æ—¶ {construction_time:.2f}ç§’")
                actual_n_clusters = kmeans_hnsw.n_clusters

                # Phase 1: Baseline HNSW
                base_ef = base_index._ef_construction
                print(f"  ä½¿ç”¨base_indexçš„ef_constructionå‚æ•°: {base_ef}")
                for k in k_values:
                    b_eval = self.evaluate_hnsw_baseline(base_index, k, base_ef, ground_truths[k])
                    phase_records.append({**b_eval, 'k': k})
                    print(f"  [åŸºçº¿HNSW] k={k} ef={base_ef} recall={b_eval['recall_at_k']:.4f} avg_time={b_eval['avg_query_time_ms']:.2f}ms")

                # Phase 2: Pure KMeans (reuse clustering)
                print(f"  ä½¿ç”¨ä¸KMeansHNSWç›¸åŒçš„èšç±»å‚æ•°: n_clusters={actual_n_clusters}")
                for k in k_values:
                    for n_probe in n_probe_values:
                        c_eval = self._evaluate_pure_kmeans_from_existing(
                            kmeans_hnsw,
                            k,
                            ground_truths[k],
                            n_probe=n_probe
                        )
                        c_eval['phase'] = 'clusters_only'
                        phase_records.append({**c_eval, 'k': k})
                        print(f"  [ä»…K-Meansèšç±»] k={k} n_probe={n_probe} recall={c_eval['recall_at_k']:.4f} avg_time={c_eval['avg_query_time_ms']:.2f}ms")

                # Phase 3: Level-based Hybrid HNSW
                if enable_hybrid:
                    print(f"  æ„å»ºå¹¶è¯„ä¼°Hybrid HNSW (parent_level={hybrid_parent_level}, k_children={params['k_children']})")
                    try:
                        hybrid_build_start = time.time()
                        hybrid_index = HNSWHybrid(
                            base_index=base_index,
                            parent_level=hybrid_parent_level,
                            k_children=params['k_children'],
                            approx_ef=params.get('child_search_ef'),
                            parent_child_method='approx',
                            diversify_max_assignments=adaptive_config.get('diversify_max_assignments'),
                            repair_min_assignments=adaptive_config.get('repair_min_assignments'),
                            adaptive_k_children=adaptive_config.get('adaptive_k_children', False),
                            k_children_scale=adaptive_config.get('k_children_scale', 1.5),
                            k_children_min=adaptive_config.get('k_children_min', 100),
                            k_children_max=adaptive_config.get('k_children_max')
                        )
                        hybrid_build_time = time.time() - hybrid_build_start
                        hybrid_stats = hybrid_index.get_stats()
                        print(f"    Hybridæ„å»ºç»Ÿè®¡: {hybrid_stats.get('num_parents', 0)} parents, "
                              f"{hybrid_stats.get('num_children', 0)} children, "
                              f"coverage: {hybrid_stats.get('coverage_fraction', 0):.4f}")
                        
                        for k in k_values:
                            for n_probe in n_probe_values:
                                h_eval = self.evaluate_hybrid_hnsw(hybrid_index, k, n_probe, ground_truths[k])
                                h_eval['hybrid_build_time'] = hybrid_build_time
                                h_eval['hybrid_k_children'] = hybrid_stats.get('k_children', params['k_children'])
                                phase_records.append({**h_eval, 'k': k})
                                print(f"  [Hybrid(Level)] k={k} n_probe={n_probe} recall={h_eval['recall_at_k']:.4f} avg_time={h_eval['avg_query_time_ms']:.2f}ms")
                    except Exception as he:
                        print(f"  âš ï¸ Hybrid HNSW æ„å»ºæˆ–è¯„ä¼°å¤±è´¥: {he}")

                # Phase 4: Single-pivot KMeans-HNSW hybrid
                for k in k_values:
                    for n_probe in n_probe_values:
                        eval_result = self.evaluate_recall(kmeans_hnsw, k, n_probe, ground_truths[k])
                        phase_records.append({**eval_result, 'phase': 'kmeans_hnsw_single_pivot'})
                        print(f"  [K-Means HNSWå•æ¢çº½] k={k} n_probe={n_probe} recall={eval_result['recall_at_k']:.4f} avg_time={eval_result['avg_query_time_ms']:.2f}ms")

                # Phase 5: Multi-pivot KMeans-HNSW hybrid
                if multi_pivot_config.get('enabled', False):
                    print(f"  æ„å»ºå¹¶è¯„ä¼°Multi-Pivot KMeans HNSW (num_pivots={multi_pivot_config.get('num_pivots', 3)})")
                    try:
                        mp_build_start = time.time()
                        multi_pivot_system = KMeansHNSWMultiPivot(
                            base_index=base_index,
                            n_clusters=params['n_clusters'],
                            k_children=params['k_children'],
                            child_search_ef=params.get('child_search_ef'),
                            # Multi-pivot specific parameters
                            num_pivots=multi_pivot_config.get('num_pivots', 3),
                            pivot_selection_strategy=multi_pivot_config.get('pivot_selection_strategy', 'line_perp_third'),
                            pivot_overquery_factor=multi_pivot_config.get('pivot_overquery_factor', 1.2),
                            multi_pivot_enabled=True,
                            store_pivot_debug=True,
                            # Adaptive/diversify/repair config
                            adaptive_k_children=adaptive_config['adaptive_k_children'],
                            k_children_scale=adaptive_config['k_children_scale'],
                            k_children_min=adaptive_config['k_children_min'],
                            k_children_max=adaptive_config['k_children_max'],
                            diversify_max_assignments=adaptive_config['diversify_max_assignments'],
                            repair_min_assignments=adaptive_config['repair_min_assignments']
                        )
                        mp_build_time = time.time() - mp_build_start
                        mp_stats = multi_pivot_system.get_stats()
                        print(f"    Multi-Pivotæ„å»ºç»Ÿè®¡: n_clusters={mp_stats.get('n_clusters', 0)}, "
                              f"avg_children={mp_stats.get('avg_children_per_cluster', 0):.1f}")
                        
                        for k in k_values:
                            for n_probe in n_probe_values:
                                mp_eval = self.evaluate_multi_pivot_recall(multi_pivot_system, k, n_probe, ground_truths[k])
                                mp_eval['phase'] = 'kmeans_hnsw_multi_pivot'
                                mp_eval['multi_pivot_build_time'] = mp_build_time
                                mp_eval['multi_pivot_config'] = multi_pivot_config
                                phase_records.append({**mp_eval, 'k': k})
                                print(f"  [K-Means HNSWå¤šæ¢çº½] k={k} n_probe={n_probe} recall={mp_eval['recall_at_k']:.4f} avg_time={mp_eval['avg_query_time_ms']:.2f}ms")
                    except Exception as me:
                        print(f"  âš ï¸ Multi-Pivot KMeans HNSW æ„å»ºæˆ–è¯„ä¼°å¤±è´¥: {me}")

                combination_results = {
                    'parameters': params,
                    'construction_time': construction_time,
                    'phase_evaluations': phase_records,
                    'multi_pivot_enabled': multi_pivot_config.get('enabled', False)
                }
                results.append(combination_results)
                best_recall = max(r['recall_at_k'] for r in phase_records if 'recall_at_k' in r)
                print(f"  æ­¤ç»„åˆæœ€ä½³å¬å›ç‡: {best_recall:.4f}")
                
            except Exception as e:
                print(f"âŒ å‚æ•°ç»„åˆ {params} å‡ºé”™: {e}")
                continue

        print(f"\nğŸ¯ å‚æ•°æ‰«æå®Œæˆï¼æµ‹è¯•äº† {len(results)} ä¸ªç»„åˆ")
        print(f"    åŒ…å«Multi-Pivotè¯„ä¼°: {multi_pivot_config.get('enabled', False)}")
        return results


def save_results(results: Dict[str, Any], filename: str):
    """Save evaluation results to JSON file."""
    # Convert numpy arrays to lists for JSON serialization
    def convert_numpy(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, dict):
            return {k: convert_numpy(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy(item) for item in obj]
        return obj
    
    results_serializable = convert_numpy(results)
    
    with open(filename, 'w') as f:
        json.dump(results_serializable, f, indent=2)
    
    print(f"Results saved to {filename}")


def load_sift_data():
    """
    åŠ è½½SIFTæ•°æ®é›†ç”¨äºè¯„ä¼° (Load SIFT dataset for evaluation)
    
    SIFT (Scale-Invariant Feature Transform) æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ç»å…¸ç‰¹å¾æè¿°ç¬¦ã€‚
    è¯¥æ•°æ®é›†åŒ…å«100ä¸‡ä¸ª128ç»´çš„ç‰¹å¾å‘é‡ï¼Œå¸¸ç”¨äºç›¸ä¼¼æ€§æœç´¢ç®—æ³•çš„åŸºå‡†æµ‹è¯•ã€‚
    
    Returns:
        tuple: (base_vectors, query_vectors) æˆ– (None, None) å¦‚æœåŠ è½½å¤±è´¥
    """
    sift_dir = os.path.join(os.path.dirname(__file__), '..', 'sift')
    
    try:
        def read_fvecs(path: str, max_vectors: Optional[int] = None) -> np.ndarray:
            """
            è¯»å–.fvecsæ–‡ä»¶ (FAISSæ ¼å¼)ã€‚æ¯ä¸ªå‘é‡å­˜å‚¨ä¸ºï¼šint32ç»´åº¦ + ç»´åº¦ä¸ªfloat32å€¼ã€‚
            
            Read .fvecs file (FAISS format). Each vector stored as: int32 dim + dim float32.
            """
            if not os.path.exists(path):
                raise FileNotFoundError(path)
            raw = np.fromfile(path, dtype=np.int32)
            if raw.size == 0:
                raise ValueError(f"ç©ºçš„fvecsæ–‡ä»¶: {path}")
            dim = raw[0]
            if dim <= 0 or dim > 4096:
                raise ValueError(f"ä¸åˆç†çš„å‘é‡ç»´åº¦ {dim}ï¼Œè§£æè‡ª {path}")
            record_size = dim + 1
            count = raw.size // record_size
            raw = raw.reshape(count, record_size)
            vecs = raw[:, 1:].astype(np.float32)
            if max_vectors is not None and count > max_vectors:
                vecs = vecs[:max_vectors]
            return vecs

        base_path = os.path.join(sift_dir, 'sift_base.fvecs')
        query_path = os.path.join(sift_dir, 'sift_query.fvecs')

        # ä¸ºè°ƒä¼˜æ¼”ç¤ºé™åˆ¶æ•°é‡ä»¥ä¿æŒåˆç†çš„è¿è¡Œæ—¶é—´
        base_vectors = read_fvecs(base_path, max_vectors=50000)
        query_vectors = read_fvecs(query_path, max_vectors=1000)

        print(f"å·²åŠ è½½SIFTæ•°æ®: {base_vectors.shape[0]} ä¸ªåŸºç¡€å‘é‡, "
              f"{query_vectors.shape[0]} ä¸ªæŸ¥è¯¢å‘é‡, ç»´åº¦ {base_vectors.shape[1]}")

        return base_vectors, query_vectors
    
    except Exception as e:
        print(f"åŠ è½½SIFTæ•°æ®æ—¶å‡ºé”™: {e}")
        print("æ”¹ç”¨åˆæˆæ•°æ®...")
        return None, None


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="K-Means HNSW + Multi-Pivotå‚æ•°è°ƒä¼˜å’Œè¯„ä¼°")
    
    # æ•°æ®é›†é€‰é¡¹
    parser.add_argument('--dataset-size', type=int, default=10000, 
                        help='ä½¿ç”¨çš„åŸºç¡€å‘é‡æ•°é‡ (é»˜è®¤: 10000)')
    parser.add_argument('--query-size', type=int, default=50, 
                        help='ä½¿ç”¨çš„æŸ¥è¯¢å‘é‡æ•°é‡ (é»˜è®¤: 50)')
    parser.add_argument('--dimension', type=int, default=128, 
                        help='åˆæˆæ•°æ®çš„å‘é‡ç»´åº¦')
    parser.add_argument('--no-sift', action='store_true', 
                        help='å¼ºåˆ¶ä½¿ç”¨åˆæˆæ•°æ®ï¼Œå³ä½¿SIFTæ–‡ä»¶å­˜åœ¨')
    
    # è‡ªé€‚åº”/å¤šæ ·åŒ–/ä¿®å¤é€‰é¡¹
    parser.add_argument('--adaptive-k-children', action='store_true', 
                        help='å¯ç”¨åŸºäºå¹³å‡èšç±»å¤§å°çš„è‡ªé€‚åº”k_children')
    parser.add_argument('--k-children-scale', type=float, default=1.5, 
                        help='è‡ªé€‚åº”k_childrençš„ç¼©æ”¾å› å­ (é»˜è®¤1.5)')
    parser.add_argument('--k-children-min', type=int, default=100, 
                        help='è‡ªé€‚åº”æ—¶çš„æœ€å°k_children')
    parser.add_argument('--k-children-max', type=int, default=None, 
                        help='è‡ªé€‚åº”æ—¶çš„æœ€å¤§k_children (å¯é€‰)')
    parser.add_argument('--diversify-max-assignments', type=int, default=None, 
                        help='æ¯ä¸ªå­èŠ‚ç‚¹çš„æœ€å¤§åˆ†é…æ•° (å¯ç”¨å¤šæ ·åŒ–)')
    parser.add_argument('--repair-min-assignments', type=int, default=None, 
                        help='æ„å»ºä¿®å¤æœŸé—´æ¯ä¸ªå­èŠ‚ç‚¹çš„æœ€å°åˆ†é…æ•°')
    parser.add_argument('--hybrid-parent-level', type=int, default=2,
                        help='Hybrid HNSW çˆ¶èŠ‚ç‚¹å±‚çº§ (é»˜è®¤:2)')
    parser.add_argument('--no-hybrid', action='store_true',
                        help='ç¦ç”¨Hybrid HNSWè¯„ä¼°')
    
    # Multi-pivot ç‰¹å®šé€‰é¡¹
    parser.add_argument('--enable-multi-pivot', action='store_true',
                        help='å¯ç”¨Multi-Pivot KMeans HNSWè¯„ä¼°')
    parser.add_argument('--num-pivots', type=int, default=3,
                        help='æ¯ä¸ªèšç±»çš„æ¢çº½ç‚¹æ•°é‡ (é»˜è®¤: 3)')
    parser.add_argument('--pivot-selection-strategy', type=str, default='line_perp_third',
                        choices=['line_perp_third', 'max_min_distance'],
                        help='æ¢çº½ç‚¹é€‰æ‹©ç­–ç•¥')
    parser.add_argument('--pivot-overquery-factor', type=float, default=1.2,
                        help='æ¢çº½æŸ¥è¯¢çš„è¿‡åº¦æŸ¥è¯¢å› å­ (é»˜è®¤: 1.2)')
    
    args = parser.parse_args()

    print("ğŸ”¬ K-Means HNSW + Multi-Pivotå‚æ•°è°ƒä¼˜å’Œè¯„ä¼°ç³»ç»Ÿ")
    print(f"ğŸ“Š è¯·æ±‚çš„æ•°æ®é›†å¤§å°: {args.dataset_size}, æŸ¥è¯¢å¤§å°: {args.query_size}")
    print(f"ğŸ¯ Multi-Pivotå¯ç”¨çŠ¶æ€: {args.enable_multi_pivot}")
    
    # å°è¯•åŠ è½½SIFTæ•°æ®ï¼Œå¤±è´¥åˆ™ä½¿ç”¨åˆæˆæ•°æ®
    base_vectors, query_vectors = (None, None)
    if not args.no_sift:
        base_vectors, query_vectors = load_sift_data()
    
    if base_vectors is None:
        # åˆ›å»ºåˆæˆæ•°æ®
        print("ğŸ² åˆ›å»ºåˆæˆæ•°æ®é›†...")
        base_vectors = np.random.randn(max(args.dataset_size, 10000), args.dimension).astype(np.float32)
        query_vectors = np.random.randn(max(args.query_size, 100), args.dimension).astype(np.float32)
    
    # åˆ‡ç‰‡åˆ°è¯·æ±‚çš„å¤§å°
    if len(base_vectors) > args.dataset_size:
        base_vectors = base_vectors[:args.dataset_size]
    if len(query_vectors) > args.query_size:
        query_vectors = query_vectors[:args.query_size]
    print(f"ğŸ“ˆ ä½¿ç”¨åŸºç¡€å‘é‡: {len(base_vectors)} | æŸ¥è¯¢: {len(query_vectors)} | ç»´åº¦: {base_vectors.shape[1]}")
    query_ids = list(range(len(query_vectors)))
    
    # è·ç¦»å‡½æ•°
    distance_func = lambda x, y: np.linalg.norm(x - y)
    
    # æ„å»ºåŸºç¡€HNSWç´¢å¼•
    print("ğŸ—ï¸  æ„å»ºåŸºç¡€HNSWç´¢å¼•...")
    base_index = HNSW(distance_func=distance_func, m=16, ef_construction=200)
    
    for i, vector in enumerate(base_vectors):
        base_index.insert(i, vector)
        if (i + 1) % 1000 == 0:
            print(f"  Inserted {i + 1}/{len(base_vectors)} vectors")
    
    print(f"Base HNSW index built with {len(base_index)} vectors")
    
    # Initialize evaluator
    evaluator = KMeansHNSWMultiPivotEvaluator(base_vectors, query_vectors, query_ids, distance_func)
    
    # Define parameter grid for sweep
    if args.dataset_size <= 2000:
        cluster_options = [10]
    elif args.dataset_size <= 5000:
        cluster_options = [16, 32]
    else:
        cluster_options = [32, 64, 128]

    param_grid = {
        'n_clusters': cluster_options,
        'k_children': [200],
        'child_search_ef': [300]
    }
    
    evaluation_params = {
        'k_values': [10],
        'n_probe_values': [5, 10, 20],
        'hybrid_parent_level': args.hybrid_parent_level,
        'enable_hybrid': (not args.no_hybrid)
    }
    
    # å‡†å¤‡è‡ªé€‚åº”é…ç½®
    adaptive_config = {
        'adaptive_k_children': args.adaptive_k_children,
        'k_children_scale': args.k_children_scale,
        'k_children_min': args.k_children_min,
        'k_children_max': args.k_children_max,
        'diversify_max_assignments': args.diversify_max_assignments,
        'repair_min_assignments': args.repair_min_assignments
    }
    
    # å‡†å¤‡Multi-Pivoté…ç½®
    multi_pivot_config = {
        'enabled': args.enable_multi_pivot,
        'num_pivots': args.num_pivots,
        'pivot_selection_strategy': args.pivot_selection_strategy,
        'pivot_overquery_factor': args.pivot_overquery_factor
    }
    
    # Perform parameter sweep
    print("\nStarting parameter sweep...")
    max_combos = 9 if len(cluster_options) > 1 else None
    
    sweep_results = evaluator.parameter_sweep(
        base_index,
        param_grid,
        evaluation_params,
        max_combinations=max_combos,
        adaptive_config=adaptive_config,
        multi_pivot_config=multi_pivot_config
    )
    
    # Save results
    if sweep_results:
        demo_result = sweep_results[0]
        demo_params = demo_result['parameters']
        print(f"\nUsing first parameter combination for demonstration: {demo_params}")
        print("\nğŸ¯ Parameter sweep completed! All comparisons (including Multi-Pivot) are available in sweep_results.")

        results = {
            'sweep_results': sweep_results,
            'demo_parameters': demo_params,
            'multi_pivot_config': multi_pivot_config,
            'adaptive_config': adaptive_config,
            'evaluation_info': {
                'dataset_size': len(base_vectors),
                'query_size': len(query_vectors),
                'dimension': base_vectors.shape[1],
                'multi_pivot_enabled': args.enable_multi_pivot,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }
        }
        save_results(results, 'multi_pivot_parameter_sweep.json')
        
    print(f"\nâœ… Multi-Pivot parameter tuning completed!")
    if args.enable_multi_pivot:
        print("ğŸ¯ Five-method comparison results saved:")
        print("   1. HNSWåŸºçº¿ (HNSW Baseline)")
        print("   2. çº¯K-Means (Pure K-Means)")
        print("   3. Hybrid HNSW")  
        print("   4. KMeans HNSW (å•æ¢çº½)")
        print("   5. Multi-Pivot KMeans HNSW (å¤šæ¢çº½)")
    else:
        print("ğŸ’¡ æç¤º: ä½¿ç”¨ --enable-multi-pivot å¯ç”¨Multi-Pivotæ–¹æ¡ˆçš„å¯¹æ¯”è¯„ä¼°")
