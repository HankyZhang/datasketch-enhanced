# HNSW + K-Means 混合检索系统

## 项目概述

本项目是一个基于HNSW（层次化小世界网络）和K-Means聚类的混合检索系统，专门用于大规模向量相似性搜索。系统采用两阶段检索策略，在保证高召回率的同时显著提升搜索效率。

## 核心算法

### 1. 基础技术栈
- **HNSW算法**：构建分层图索引，实现快速近似最近邻搜索
- **K-Means聚类**：将数据分组，形成粗粒度的父节点
- **Multi-Pivot策略**：每个聚类使用多个代表点，提升搜索精度

### 2. 检索流程
```
数据向量 → HNSW索引构建 → K-Means聚类 → 父子节点映射 → 两阶段检索
```

1. **构建阶段**：
   - 使用HNSW算法构建基础图索引
   - K-Means聚类生成质心作为父节点
   - 为每个质心分配子节点，形成层次结构

2. **检索阶段**：
   - 第一阶段：计算查询向量到各质心的距离，选择最近的n_probe个质心
   - 第二阶段：在选中质心的子节点中进行精确搜索，返回最终结果

### 3. 核心参数

| 参数 | 说明 | 推荐值 |
|------|------|--------|
| `n_clusters` | 聚类数量（质心数） | 32-128 |
| `k_children` | 每个质心的子节点数 | 1000-2000 |
| `n_probe` | 检索时探测的质心数 | 5-20 |
| `num_pivots` | 多枢纽策略的枢纽点数 | 3-5 |

## 使用方法

### 基本运行
```bash
# 使用合成数据进行测试
python method3/v1.py --dataset-size 10000 --query-size 100

# 启用Multi-Pivot策略
python method3/v1.py --enable-multi-pivot --num-pivots 3

# 使用SIFT数据集
python method3/v1.py --dataset-size 20000 --query-size 200
```

### 性能调优
```bash
# 大数据集优化配置
python method3/v1.py \
    --dataset-size 50000 \
    --query-size 500 \
    --enable-multi-pivot \
    --adaptive-k-children \
    --repair-min-assignments 2
```

## 性能指标

系统主要评估以下性能指标：

- **召回率 (Recall)**：检索结果的准确性
- **查询时间**：单次检索的平均耗时
- **覆盖率 (Coverage)**：系统对数据的覆盖程度
- **重复率 (Duplication)**：节点分配的重复情况

## 技术优势

1. **高效性**：两阶段检索大幅减少计算开销
2. **准确性**：Multi-Pivot策略提升检索精度
3. **可扩展性**：支持大规模数据集处理
4. **灵活性**：多种策略可配置调优

## 应用场景

- 图像检索系统
- 文档相似性搜索
- 推荐系统
- 音频/视频内容匹配
- 大规模特征匹配

## 技术架构

```
输入数据
    ↓
HNSW基础索引
    ↓
K-Means聚类
    ↓
Multi-Pivot策略
    ↓
两阶段检索引擎
    ↓
检索结果
```

## 系统要求

- Python 3.7+
- NumPy
- scikit-learn
- 内存：建议8GB以上（取决于数据规模）
