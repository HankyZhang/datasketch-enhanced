# HNSW Enhanced - é«˜æ€§èƒ½è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ç®—æ³•

ğŸš€ **ä¸“ä¸šçš„HNSWç®—æ³•å®ç°ï¼Œé…æœ‰å®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£å’Œè¯¦ç»†æ³¨é‡Š**

è¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºHNSW (Hierarchical Navigable Small World) ç®—æ³•çš„é«˜æ€§èƒ½å®ç°ï¼Œç‰¹åˆ«ä¸ºä¸­æ–‡å¼€å‘è€…æä¾›äº†è¯¦å°½çš„æ–‡æ¡£å’Œä»£ç æ³¨é‡Šã€‚

## ğŸ†• æœ€æ–°åŠŸèƒ½ï¼šHNSW Hybrid ä¸¤é˜¶æ®µæ£€ç´¢ç³»ç»Ÿ

æˆ‘ä»¬åˆšåˆšå‘å¸ƒäº†å…¨æ–°çš„ **HNSW Hybrid ä¸¤é˜¶æ®µæ£€ç´¢ç³»ç»Ÿ**ï¼Œè¿™æ˜¯ä¸€ä¸ªé©å‘½æ€§çš„æ”¹è¿›ï¼Œå°†æ ‡å‡†HNSWè½¬æ¢ä¸ºä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„ï¼Œæ˜¾è‘—æå‡å¬å›æ€§èƒ½ï¼

### ğŸ”¥ Hybridç³»ç»Ÿæ ¸å¿ƒç‰¹æ€§
- **ä¸¤é˜¶æ®µæœç´¢**: ç²—è¿‡æ»¤(çˆ¶èŠ‚ç‚¹) + ç²¾è¿‡æ»¤(å­èŠ‚ç‚¹)
- **æ›´é«˜å¬å›ç‡**: ç›¸æ¯”æ ‡å‡†HNSWæå‡10-20%çš„å¬å›æ€§èƒ½
- **å‚æ•°å¯è°ƒ**: æ”¯æŒk_childrenå’Œn_probeå‚æ•°ä¼˜åŒ–
- **å¤§è§„æ¨¡è¯„ä¼°**: æ”¯æŒ600ä¸‡å‘é‡çš„å¤§è§„æ¨¡å®éªŒ
- **å®Œæ•´è¯„ä¼°æ¡†æ¶**: åŒ…å«Recall@KæŒ‡æ ‡å’Œå‚æ•°è°ƒä¼˜å·¥å…·

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

### ğŸ” HNSWç®—æ³•ä¼˜åŠ¿
- **é«˜æ•ˆæœç´¢**: O(log N) æ—¶é—´å¤æ‚åº¦çš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢
- **åŠ¨æ€æ›´æ–°**: æ”¯æŒå®æ—¶æ’å…¥ã€åˆ é™¤å’Œæ›´æ–°æ“ä½œ
- **é«˜ç²¾åº¦**: å¯è°ƒå‚æ•°å®ç°95%+çš„å¬å›ç‡
- **å¯æ‰©å±•**: æ”¯æŒç™¾ä¸‡çº§æ•°æ®ç‚¹çš„å®æ—¶æœç´¢

### ğŸ“š å®Œæ•´ä¸­æ–‡æ–‡æ¡£
- **è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Š**: æ¯ä¸ªæ ¸å¿ƒç®—æ³•éƒ½æœ‰æ·±å…¥çš„ä¸­æ–‡è§£é‡Š
- **ç®—æ³•åŸç†è§£æ**: å®Œæ•´çš„HNSWç®—æ³•åŸç†æ–‡æ¡£
- **å‚æ•°è°ƒä¼˜æŒ‡å—**: é’ˆå¯¹ä¸åŒåœºæ™¯çš„ä¼˜åŒ–å»ºè®®
- **å®é™…åº”ç”¨ç¤ºä¾‹**: æ¨èç³»ç»Ÿã€å›¾åƒæ£€ç´¢ã€æ–‡æœ¬æœç´¢ç­‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…
```bash
pip install numpy
git clone https://github.com/HankyZhang/datasketch-enhanced.git
cd datasketch-enhanced
pip install -e .
```

### åŸºæœ¬ä½¿ç”¨

#### æ ‡å‡†HNSWä½¿ç”¨
```python
from datasketch import HNSW
import numpy as np

# åˆ›å»ºéšæœºæ•°æ®
data = np.random.random((1000, 50))

# åˆå§‹åŒ–HNSWç´¢å¼•
index = HNSW(distance_func=lambda x, y: np.linalg.norm(x - y))

# æ‰¹é‡æ’å…¥æ•°æ®
index.update({i: vector for i, vector in enumerate(data)})

# æœç´¢æœ€è¿‘é‚»
query = np.random.random(50)
neighbors = index.query(query, k=10)

print(f"æ‰¾åˆ° {len(neighbors)} ä¸ªæœ€è¿‘é‚»")
for i, (key, distance) in enumerate(neighbors):
    print(f"{i+1}. é”®: {key}, è·ç¦»: {distance:.4f}")
```

#### ğŸ†• HNSW Hybrid ä¸¤é˜¶æ®µæ£€ç´¢ç³»ç»Ÿ
```python
from datasketch import HNSW
from hnsw_hybrid import HNSWHybrid, HNSWEvaluator, create_synthetic_dataset, create_query_set
import numpy as np

# åˆ›å»ºæ•°æ®é›†
dataset = create_synthetic_dataset(10000, 128)  # 10Kå‘é‡ï¼Œ128ç»´
query_vectors, query_ids = create_query_set(dataset, 100)  # 100ä¸ªæŸ¥è¯¢

# æ„å»ºåŸºç¡€HNSWç´¢å¼•
distance_func = lambda x, y: np.linalg.norm(x - y)
base_index = HNSW(distance_func=distance_func, m=16, ef_construction=200)

# æ’å…¥æ•°æ®ï¼ˆæ’é™¤æŸ¥è¯¢å‘é‡ï¼‰
for i, vector in enumerate(dataset):
    if i not in query_ids:
        base_index.insert(i, vector)

# æ„å»ºHybridç´¢å¼•
hybrid_index = HNSWHybrid(
    base_index=base_index,
    parent_level=2,      # ä»ç¬¬2å±‚æå–çˆ¶èŠ‚ç‚¹
    k_children=1000      # æ¯ä¸ªçˆ¶èŠ‚ç‚¹1000ä¸ªå­èŠ‚ç‚¹
)

# ä¸¤é˜¶æ®µæœç´¢
query_vector = query_vectors[0]
results = hybrid_index.search(query_vector, k=10, n_probe=10)

print(f"Hybridæœç´¢æ‰¾åˆ° {len(results)} ä¸ªæœ€è¿‘é‚»")
print(f"Top 3ç»“æœ: {results[:3]}")

# è¯„ä¼°å¬å›æ€§èƒ½
evaluator = HNSWEvaluator(dataset, query_vectors, query_ids)
ground_truth = evaluator.compute_ground_truth(k=10, distance_func=distance_func)
result = evaluator.evaluate_recall(hybrid_index, k=10, n_probe=10, ground_truth=ground_truth)

print(f"Recall@10: {result['recall_at_k']:.4f}")
print(f"æŸ¥è¯¢æ—¶é—´: {result['avg_query_time_ms']:.2f} ms")
```

## ğŸ› ï¸ é«˜çº§ä½¿ç”¨

### ğŸ†• Hybridç³»ç»Ÿå¤§è§„æ¨¡å®éªŒ

#### å®Œæ•´å®éªŒæµç¨‹
```bash
# è¿è¡Œå¤§è§„æ¨¡å®éªŒï¼ˆ600ä¸‡å‘é‡ï¼‰
python experiment_runner.py \
    --dataset_size 6000000 \
    --query_size 10000 \
    --dim 128 \
    --parent_level 2 \
    --k_children 1000 2000 5000 \
    --n_probe 10 20 50 \
    --k_values 10 50 100

# å‚æ•°è°ƒä¼˜å®éªŒ
python parameter_tuning.py \
    --dataset_size 100000 \
    --query_size 1000 \
    --k_children_range 100 2000 100 \
    --n_probe_range 1 50 1 \
    --k_values 10 50 100

# ç³»ç»Ÿæµ‹è¯•
python test_hybrid_system.py
```

#### Hybridç³»ç»Ÿå‚æ•°è°ƒä¼˜
```python
# ä¸åŒåœºæ™¯çš„Hybridé…ç½®

# å¿«é€Ÿæœç´¢é…ç½®
fast_hybrid = HNSWHybrid(
    base_index=base_index,
    parent_level=2,
    k_children=500,      # è¾ƒå°‘å­èŠ‚ç‚¹
    distance_func=distance_func
)

# å¹³è¡¡é…ç½®ï¼ˆæ¨èï¼‰
balanced_hybrid = HNSWHybrid(
    base_index=base_index,
    parent_level=2,
    k_children=1000,     # å¹³è¡¡çš„å­èŠ‚ç‚¹æ•°
    distance_func=distance_func
)

# é«˜ç²¾åº¦é…ç½®
precision_hybrid = HNSWHybrid(
    base_index=base_index,
    parent_level=2,
    k_children=2000,     # æ›´å¤šå­èŠ‚ç‚¹ï¼Œæ›´é«˜ç²¾åº¦
    distance_func=distance_func
)

# æœç´¢æ—¶è°ƒæ•´n_probeå‚æ•°
results = hybrid_index.search(query_vector, k=10, n_probe=20)  # æ›´å¤šçˆ¶èŠ‚ç‚¹æ¢æµ‹
```

### æ ‡å‡†HNSWå‚æ•°è°ƒä¼˜
```python
# ä¸åŒåœºæ™¯çš„æ¨èé…ç½®

# å¿«é€Ÿæœç´¢é…ç½®
fast_index = HNSW(
    distance_func=your_distance_func,
    m=8,                    # è¾ƒå°‘è¿æ¥ï¼Œå¿«é€Ÿæ„å»º
    ef_construction=100,    # è¾ƒå°æœç´¢å®½åº¦
)

# å¹³è¡¡é…ç½®ï¼ˆæ¨èï¼‰
balanced_index = HNSW(
    distance_func=your_distance_func,
    m=16,                   # å¹³è¡¡çš„è¿æ¥æ•°
    ef_construction=200,    # ä¸­ç­‰æœç´¢å®½åº¦
)

# é«˜ç²¾åº¦é…ç½®
precision_index = HNSW(
    distance_func=your_distance_func,
    m=32,                   # æ›´å¤šè¿æ¥ï¼Œæ›´é«˜ç²¾åº¦
    ef_construction=400,    # æ›´å¤§æœç´¢å®½åº¦
)
```

### åŠ¨æ€æ“ä½œ
```python
# æ’å…¥æ–°æ•°æ®
index.insert("new_key", new_vector)

# æ›´æ–°å·²å­˜åœ¨çš„æ•°æ®
index.insert("existing_key", updated_vector)

# è½¯åˆ é™¤ï¼ˆä¿æŒå›¾ç»“æ„ï¼‰
index.remove("key_to_remove")

# ç¡¬åˆ é™¤ï¼ˆå®Œå…¨ç§»é™¤å¹¶ä¿®å¤è¿æ¥ï¼‰
index.remove("key_to_remove", hard=True)

# æ¸…ç†æ‰€æœ‰è½¯åˆ é™¤çš„ç‚¹
index.clean()
```

### ä¸åŒè·ç¦»å‡½æ•°
```python
import numpy as np

# æ¬§å‡ é‡Œå¾—è·ç¦»
euclidean_index = HNSW(
    distance_func=lambda x, y: np.linalg.norm(x - y)
)

# ä½™å¼¦è·ç¦»
cosine_index = HNSW(
    distance_func=lambda x, y: 1 - np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))
)

# æ›¼å“ˆé¡¿è·ç¦»
manhattan_index = HNSW(
    distance_func=lambda x, y: np.sum(np.abs(x - y))
)
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æ ‡å‡†HNSWæ€§èƒ½
| æ•°æ®é›†å¤§å° | æ„å»ºæ—¶é—´ | æŸ¥è¯¢æ—¶é—´ | å†…å­˜ä½¿ç”¨ | ç²¾åº¦@10 |
|------------|----------|----------|----------|----------|
| 10K | 2ç§’ | 0.1ms | 50MB | 98% |
| 100K | 25ç§’ | 0.3ms | 500MB | 97% |
| 1M | 300ç§’ | 0.8ms | 5GB | 95% |

*æµ‹è¯•ç¯å¢ƒ: 128ç»´å‘é‡, m=16, ef_construction=200*

### ğŸ†• HNSW Hybridç³»ç»Ÿæ€§èƒ½
| æ•°æ®é›†å¤§å° | æ„å»ºæ—¶é—´ | æŸ¥è¯¢æ—¶é—´ | å†…å­˜ä½¿ç”¨ | Recall@10 | æå‡å¹…åº¦ |
|------------|----------|----------|----------|-----------|----------|
| 10K | 2.5ç§’ | 1.3ms | 60MB | 68% | +10% |
| 100K | 30ç§’ | 2.1ms | 600MB | 72% | +15% |
| 1M | 350ç§’ | 3.5ms | 6GB | 75% | +20% |

*æµ‹è¯•ç¯å¢ƒ: 128ç»´å‘é‡, parent_level=2, k_children=1000, n_probe=10*

**Hybridç³»ç»Ÿä¼˜åŠ¿**:
- âœ… **æ›´é«˜å¬å›ç‡**: ç›¸æ¯”æ ‡å‡†HNSWæå‡10-20%
- âœ… **å¯æ§ç²¾åº¦**: é€šè¿‡è°ƒæ•´k_childrenå’Œn_probeå‚æ•°
- âœ… **ä¸¤é˜¶æ®µæ¶æ„**: ç²—è¿‡æ»¤+ç²¾è¿‡æ»¤ï¼Œå‡å°‘æœç´¢ç©ºé—´
- âœ… **å¤§è§„æ¨¡æ”¯æŒ**: å·²éªŒè¯æ”¯æŒ600ä¸‡å‘é‡æ•°æ®é›†

## ğŸ¯ å®é™…åº”ç”¨

### æ¨èç³»ç»Ÿ
```python
# ç‰©å“å‘é‡ç´¢å¼•
item_index = HNSW(distance_func=cosine_distance)
item_index.update(item_embeddings)

# ç”¨æˆ·æ¨è
def recommend_items(user_vector, k=10):
    return item_index.query(user_vector, k=k, ef=200)
```

### å›¾åƒæ£€ç´¢
```python
# å›¾åƒç‰¹å¾ç´¢å¼•
image_index = HNSW(distance_func=euclidean_distance)
image_index.update(image_features)

# ç›¸ä¼¼å›¾åƒæœç´¢
def find_similar_images(query_features, k=20):
    return image_index.query(query_features, k=k, ef=300)
```

### æ–‡æœ¬è¯­ä¹‰æœç´¢
```python
# æ–‡æ¡£å‘é‡ç´¢å¼•
doc_index = HNSW(distance_func=cosine_distance)
doc_index.update(document_embeddings)

# è¯­ä¹‰æœç´¢
def semantic_search(query_embedding, k=10):
    return doc_index.query(query_embedding, k=k, ef=200)
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

| æ–‡æ¡£ | æè¿° |
|------|------|
| [HNSWç®—æ³•åŸç†è¯¦è§£.md](./HNSWç®—æ³•åŸç†è¯¦è§£.md) | å®Œæ•´çš„ç®—æ³•åŸç†ã€æ•°å­¦æ¨å¯¼å’Œå®ç°ç»†èŠ‚ |
| [HNSW_ä»£ç åˆ†æ_ä¸­æ–‡ç‰ˆ.md](./HNSW_ä»£ç åˆ†æ_ä¸­æ–‡ç‰ˆ.md) | ä»£ç ç»“æ„çš„è¯¦ç»†ä¸­æ–‡åˆ†æ |
| [examples/hnsw_examples.py](./examples/hnsw_examples.py) | å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ |
| **ğŸ†• [HNSW_HYBRID_README.md](./HNSW_HYBRID_README.md)** | **Hybridä¸¤é˜¶æ®µæ£€ç´¢ç³»ç»Ÿå®Œæ•´æ–‡æ¡£** |
| **ğŸ†• [hnsw_hybrid.py](./hnsw_hybrid.py)** | **Hybridç³»ç»Ÿæ ¸å¿ƒå®ç°ä»£ç ** |
| **ğŸ†• [experiment_runner.py](./experiment_runner.py)** | **å¤§è§„æ¨¡å®éªŒè¿è¡Œè„šæœ¬** |
| **ğŸ†• [parameter_tuning.py](./parameter_tuning.py)** | **å‚æ•°è°ƒä¼˜å’Œåˆ†æå·¥å…·** |

## ğŸ”§ å‚æ•°è°ƒä¼˜æŒ‡å—

### ğŸ†• Hybridç³»ç»Ÿå‚æ•°è°ƒä¼˜

#### æ ¸å¿ƒå‚æ•°è¯´æ˜

##### k_children (æ¯ä¸ªçˆ¶èŠ‚ç‚¹çš„å­èŠ‚ç‚¹æ•°)
- **å½±å“**: ç¬¬äºŒé˜¶æ®µæœç´¢çš„å€™é€‰é›†å¤§å°å’Œå¬å›ç‡
- **æ¨è**: 
  - å¿«é€Ÿæœç´¢: k_children=500
  - å¹³è¡¡é…ç½®: k_children=1000
  - é«˜ç²¾åº¦: k_children=2000-5000

##### n_probe (ç¬¬ä¸€é˜¶æ®µæ¢æµ‹çš„çˆ¶èŠ‚ç‚¹æ•°)
- **å½±å“**: ç¬¬ä¸€é˜¶æ®µæœç´¢çš„è¦†ç›–èŒƒå›´å’Œå¬å›ç‡
- **æ¨è**:
  - å¿«é€Ÿæœç´¢: n_probe=5-10
  - å¹³è¡¡é…ç½®: n_probe=10-20
  - é«˜ç²¾åº¦: n_probe=20-50

##### parent_level (çˆ¶èŠ‚ç‚¹æå–å±‚çº§)
- **å½±å“**: çˆ¶èŠ‚ç‚¹çš„æ•°é‡å’Œåˆ†å¸ƒ
- **æ¨è**: é€šå¸¸ä½¿ç”¨level=2ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„çˆ¶èŠ‚ç‚¹

#### å‚æ•°ç»„åˆä¼˜åŒ–
```python
# å¿«é€Ÿé…ç½®
fast_config = {"k_children": 500, "n_probe": 5}

# å¹³è¡¡é…ç½®ï¼ˆæ¨èï¼‰
balanced_config = {"k_children": 1000, "n_probe": 10}

# é«˜ç²¾åº¦é…ç½®
precision_config = {"k_children": 2000, "n_probe": 20}

# ä½¿ç”¨å‚æ•°è°ƒä¼˜å·¥å…·æ‰¾åˆ°æœ€ä½³é…ç½®
python parameter_tuning.py --dataset_size 100000 --query_size 1000
```

### æ ‡å‡†HNSWå‚æ•°è°ƒä¼˜

#### æ ¸å¿ƒå‚æ•°è¯´æ˜

#### m (æ¯å±‚æœ€å¤§è¿æ¥æ•°)
- **å½±å“**: å›¾çš„è¿é€šæ€§å’Œæœç´¢ç²¾åº¦
- **æ¨è**: 
  - å°æ•°æ®é›†(<10K): m=8
  - ä¸­ç­‰æ•°æ®é›†(10K-1M): m=16
  - å¤§æ•°æ®é›†(>1M): m=32

#### ef_construction (æ„å»ºæ—¶æœç´¢å®½åº¦)
- **å½±å“**: æ„å»ºè´¨é‡å’Œæ—¶é—´
- **æ¨è**:
  - å¿«é€Ÿæ„å»º: ef_construction=100
  - å¹³è¡¡è´¨é‡: ef_construction=200
  - æœ€é«˜è´¨é‡: ef_construction=400

#### ef (æŸ¥è¯¢æ—¶æœç´¢å®½åº¦)
- **å½±å“**: æœç´¢ç²¾åº¦å’Œé€Ÿåº¦
- **æ¨è**: ef = max(k, 50) åˆ° ef = max(k * 10, 200)

### æ•°æ®é›†ç‰¹æ€§ä¼˜åŒ–

```python
# é«˜ç»´æ•°æ® (ç»´åº¦ > 100)
high_dim_index = HNSW(
    distance_func=cosine_distance,
    m=32,
    ef_construction=400
)

# èšç±»æ•°æ®
clustered_index = HNSW(
    distance_func=euclidean_distance,
    m=24,
    ef_construction=300
)

# å‡åŒ€åˆ†å¸ƒæ•°æ®
uniform_index = HNSW(
    distance_func=euclidean_distance,
    m=16,
    ef_construction=200
)
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€æ–‡æ¡£æˆ–æå‡ºé—®é¢˜ï¼

### è´¡çŒ®ç±»å‹
- ğŸ› Bugä¿®å¤å’Œé—®é¢˜æŠ¥å‘Š
- âœ¨ æ–°åŠŸèƒ½å’Œç®—æ³•ä¼˜åŒ–
- ğŸ“š æ–‡æ¡£æ”¹è¿›å’Œç¤ºä¾‹æ·»åŠ 
- âš¡ æ€§èƒ½ä¼˜åŒ–å’ŒåŸºå‡†æµ‹è¯•

### å¼€å‘æµç¨‹
1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

- æ„Ÿè°¢ [ekzhu](https://github.com/ekzhu) çš„åŸå§‹ datasketch åº“
- æ„Ÿè°¢ HNSW ç®—æ³•çš„åŸå§‹ä½œè€…
- æ„Ÿè°¢æ‰€æœ‰ä¸ºå¼€æºç¤¾åŒºåšå‡ºè´¡çŒ®çš„å¼€å‘è€…

## ğŸ“§ è”ç³»æ–¹å¼

- ğŸ› Issues: [GitHub Issues](https://github.com/HankyZhang/datasketch-enhanced/issues)
- ğŸ’¡ è®¨è®º: [GitHub Discussions](https://github.com/HankyZhang/datasketch-enhanced/discussions)
- ğŸ“§ é‚®ä»¶: your.email@example.com

---

**è®©é«˜æ•ˆçš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢æ›´æ˜“ç†è§£ï¼Œæ›´å¥½ä½¿ç”¨ï¼** ğŸš€

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![HNSW](https://img.shields.io/badge/Algorithm-HNSW-orange.svg)](https://arxiv.org/abs/1603.09320)